# general settings
# name: ennet_tower # doesn't matter, only file name matters
model_type: ImageCleanModel 
scale: 1
# num_gpu: 1  # set num_gpu: 0 for cpu mode
# device: "0" # 需为单个数字

manual_seed: 42

ensemble_models: ['retinexformer', 'cidnet', 'glare', 'flw', 'lmt', 'lytnet'] # 'retinexformer', 'cidnet', 'glare', 'lytnet', 'flw', 'lmt'
dataset_name: LOLv2s
exp_note: LOLv2s

# dataset and data loader settings
datasets:
  train:
    name: TrainSet
    type: Dataset_PairedImage
    dataroot_gt: /root/autodl-tmp/ennet/datasets/LOLv2/Synthetic/Train/Normal
    dataroot_lq: /root/autodl-tmp/ennet/datasets/LOLv2/Synthetic/Train/Low
    geometric_augs: true # 开启几何数据增强
    filename_tmpl: '{}' # Template for each filename.
    io_backend:
      type: disk
    use_cache: true

    # data loader
    use_shuffle: true
    num_worker_per_gpu: 0
    batch_size_per_gpu: 4 # 
    # iters: [100000]
    dataset_enlarge_ratio: 1
    prefetch_mode: cuda
    # pin_memory: true 将加载的数据张量固定在CPU内存中以提速，但需要cpu内存足够
    ### -------------Progressive training---------------------------
    mini_batch_sizes: [4,4,4]
    iters: [30000,30000,30000]
    # gt_size: 384   # Max patch size for progressive training
    # gt_sizes: [128,160,192,256,320,384]  # Patch sizes for progressive training.
    # ### ------------------------------------------------------------

  val:
    name: ValSet
    type: Dataset_PairedImage
    dataroot_gt: /root/autodl-tmp/ennet/datasets/LOLv2/Synthetic/Test/Normal
    dataroot_lq: /root/autodl-tmp/ennet/datasets/LOLv2/Synthetic/Test/Low
    io_backend:
      type: disk
    use_cache: true


network_g:
  type: Ennet  # network name, in basicsr/models/archs/
  channels: 3
  block_size: 8
  conv_dim: 64
  kernal_sizes: [3, 5, 7, 9]
  down_channels: [48, 96,] # [18, 32, 64, 128, 192]
  emb_dim: 128
  n_layers: 2
  up_channels: [64, 16,] # [192, 96, 48, 16, 3]


# path
path:
  # moe_weight: experiments/05050100_LOLv2s_moe/models/net_g_10000.pth
  strict_load_g: true
  resume_state: ~

# 训练设置
train:
  total_iter: 90000
  warmup_iter: -1 # no warm up
  grad_clip: 1

  scheduler: # 学习率调整
    type: CosineAnnealingRestartCyclicLR # 带重启的余弦退火学习率调度
    periods: [40000, 50000]  # 每个余弦退火周期的持续时间
    restart_weights: [1,1] # 每次重启时的学习率权重
    eta_mins: [0.0002, 0.00001] # 每个周期的最小学习率值
  
  mixing_augs: # 混合增强
    mixup: true
    mixup_beta: 1.2
    use_identity: true

  optim_g: # 优化器设置
    type: Adam
    lr: !!float 2e-4
    weight_decay: !!float 1e-4
    betas: [0.9, 0.999]
  
  losses: # losses
    L1Loss:
      loss_weight: 1
      reduction: mean
    LpipsLoss:
      loss_weight: 0.5

# validation settings
val:
  # window_size: 4
  val_freq: !!float 5000
  save_img: true
  save_img_prob: 0.2
  rgb2bgr: true
  use_image: true # np if true else tensor
  max_minibatch: 8

  metrics:
    psnr: # metric name, can be arbitrary
      type: calculate_psnr
    ssim: 
      type: calculate_ssim
    lpips: 
      type: calculate_lpips
    l_pix:
      type: l1_loss

# logging settings
logger:
  print_freq: 100 #打印日志
  save_checkpoint_freq: 10000 
  use_tb_logger: true
  wandb:
    project: low_light
    resume_id: ~
